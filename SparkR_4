ML
# Machine learning functions
   a_tibble %>%
  ml_some_model("response", c("a_feature", "another_feature"), some_other_args)
Supported machine learning functions include linear regression and its variants, tree-based models (ml_decision_tree(), and a few others. You can see the list of all the machine learning functions using ls().

ls("package:sparklyr", pattern = "^ml")

> # timbre
> head(timbre)
       [,1]     [,2]    [,3]     [,4]   [,5]    [,6]    [,7]   [,8]    [,9]
[1,]  0.000  171.130   9.469  -28.480 57.491 -50.067  14.833  5.359 -27.228
[2,] 36.455 -112.873  -5.936   26.963 -8.078 170.064  19.202  7.577 -21.994
[3,] 43.744  -76.934 100.646 -111.025 29.524  60.988  78.307 28.143  30.541
[4,] 44.939 -124.457  64.221  -57.958 57.702 -12.440  17.104 11.994  49.513
[5,] 45.373  -64.408  32.393   52.271 12.202 -32.133  15.793 39.462  27.378
[6,] 43.744 -119.005  22.349  -45.255 87.264 -45.322 -10.401 11.876  91.209
       [,10]   [,11]  [,12]
[1,]   0.973 -10.640 -7.228
[2,] 107.762 100.979  1.022
[3,]  -8.286  32.603 12.203
[4,]   4.260   5.366 22.026
[5,]   0.980   5.166 38.869
[6,]   8.955  10.779 36.823
> 
> # Calculate column means
> (mean_timbre <- colMeans(timbre))
 [1]  39.244095 -39.408016  41.409616   4.748857  19.444392  22.716039
 [7] -10.596981   6.838041   3.179969   2.454293  -4.799178  12.575696
> 
#Working with parquet files. sparklyr can import parquet files using spark_read_parquet(). This function takes a Spark connection, 
a string naming the Spark DataFrame that should be created, and a path to the parquet directory. Note that this function will import the 
data directly into Spark, which is typically faster than importing the data into R, then using copy_to() to copy the data from R to Spark.
# spark_read_parquet(sc, "a_dataset", "path/to/parquet/dir")

> # parquet_dir has been pre-defined
> parquet_dir
[1] "/usr/local/share/datasets/timbre_parquet"
> 
> # List the files in the parquet dir
> filenames <- dir(parquet_dir, full.name = T)
> 
> # Show the filenames and their sizes
> data_frame(
    filename = basename(filenames),
    size_bytes =file.size(filenames) 
  )
# A tibble: 2 x 2
  filename                                                         size_bytes
  <chr>                                                                 <dbl>
1 _SUCCESS                                                                  0
2 part-r-00000-720803dc-75ed-4df7-b134-e6fdd8da5f0b.snappy.parquet     112774
> 
> # Import the data into Spark
> timbre_tbl <- spark_read_parquet(spark_conn, "timbre", parquet_dir)
> head(timbre_tbl)
# Source:   lazy query [?? x 13]
# Database: spark_connection
  track_id timbre_means1 timbre_means2 timbre_means3 timbre_means4 timbre_means5
  <chr>            <dbl>         <dbl>         <dbl>         <dbl>         <dbl>
1 TRDPMEU~          37.3         -70.2          39.4        12.7          -23.9 
2 TRDVOZX~          33.3        -137.           54.5         3.59          -4.36
3 TRDOAKS~          37.9         -17.8          54.8         3.61         -17.6 
4 TRDXVNB~          35.7        -142.           72.6        -2.23         -48.3 
5 TROHHLM~          29.1        -135.           52.2        -0.671        -32.1 
6 TROHBNM~          37.4         -89.8          47.5         6.17         -53.2 
# ... with 7 more variables: timbre_means6 <dbl>, timbre_means7 <dbl>,
#   timbre_means8 <dbl>, timbre_means9 <dbl>, timbre_means10 <dbl>,
#   timbre_means11 <dbl>, timbre_means12 <dbl>
> 

> # look at track_metadata_tbl and timbre_tbl  and join them
> track_metadata_tbl%>% head(2)
# Source:   lazy query [?? x 11]
# Database: spark_connection
  track_id title song_id release artist_id artist_mbid artist_name duration
  <chr>    <chr> <chr>   <chr>   <chr>     <chr>       <chr>          <dbl>
1 TRSTWXA~ The ~ SOCQMX~ Espana  ARNNU4G1~ 5c176092-c~ 101 Strings     221.
2 TRQNQZX~ Soul~ SOWULX~ Diary ~ ARJ9DSA1~ 4756395c-5~ John Mayal~     368.
# ... with 3 more variables: artist_familiarity <dbl>, artist_hotttnesss <dbl>,
#   year <int>
> timbre_tbl%>%head(2)
# Source:   lazy query [?? x 13]
# Database: spark_connection
  track_id timbre_means1 timbre_means2 timbre_means3 timbre_means4 timbre_means5
  <chr>            <dbl>         <dbl>         <dbl>         <dbl>         <dbl>
1 TRDPMEU~          37.3         -70.2          39.4         12.7         -23.9 
2 TRDVOZX~          33.3        -137.           54.5          3.59         -4.36
# ... with 7 more variables: timbre_means6 <dbl>, timbre_means7 <dbl>,
#   timbre_means8 <dbl>, timbre_means9 <dbl>, timbre_means10 <dbl>,
#   timbre_means11 <dbl>, timbre_means12 <dbl>
> 
> track_metadata_tbl %>%
    # Inner join to timbre_tbl
    inner_join(timbre_tbl, by = "track_id") %>%
    # Convert year to numeric
    mutate(year = as.numeric(year))
# Source:   lazy query [?? x 23]
# Database: spark_connection
   track_id title song_id release artist_id artist_mbid artist_name duration
   <chr>    <chr> <chr>   <chr>   <chr>     <chr>       <chr>          <dbl>
 1 TRDVOZX~ Jers~ SOKMEH~ Backwa~ ARDNQ0R1~ dbfd61ef-f~ Lonnie Joh~     178.
 2 TRYKNRH~ She'~ SOVEME~ Roosev~ ARFUFNK1~ 99ab25d6-7~ Roosevelt ~     174.
 3 TRTDSZA~ Blue~ SOGJBO~ Tampa ~ AR576O51~ 1b62df85-0~ Tampa Red       200.
 4 TRKYOZL~ Drop~ SOEIMR~ 1935-1~ ARE2QID1~ 3bef5827-7~ Sleepy Joh~     191.
 5 TRKIDHY~ Penn~ SOHBKZ~ Film F~ ARRL2QH1~ 2437980f-5~ Bing Crosby     192.
 6 TRWVMJQ~ Old ~ SOWJQM~ Tennes~ AR9HABI1~ aff932c2-e~ Red Foley       196.
 7 TRPNSUE~ Summ~ SODXPG~ Begin ~ ARVYGOU1~ e0e03d5f-9~ Artie Shaw~     206.
 8 TRXBTVP~ Devi~ SODACR~ Rhythm~ ARL99WU1~ f205743d-4~ Skip James      179.
 9 TRYGLKZ~ Milk~ SOBJTI~ Kokomo~ ARR6H6G1~ 74a64e96-4~ Kokomo Arn~     193.
10 TROTQNF~ Stra~ SOJXRG~ Blues ~ ARNEL2O1~ 882af819-8~ Bukka White     159.
# ... with 104 more rows, and 15 more variables: artist_familiarity <dbl>,
#   artist_hotttnesss <dbl>, timbre_means1 <dbl>, timbre_means2 <dbl>,
#   timbre_means3 <dbl>, timbre_means4 <dbl>, timbre_means5 <dbl>,
#   timbre_means6 <dbl>, timbre_means7 <dbl>, timbre_means8 <dbl>,
#   timbre_means9 <dbl>, timbre_means10 <dbl>, timbre_means11 <dbl>,
#   timbre_means12 <dbl>, year <dbl>
> 

# Partitioning data with a group effect
training_testing_artist_ids <- track_data_tbl %>%
  # Select the artist ID
  select(artist_id) %>%
  # Get distinct rows
  distinct() %>%
  # Partition into training/testing sets
  sdf_partition(training=0.7, testing = 0.3)

track_data_to_model_tbl <- track_data_tbl %>%
  # Inner join to training partition
  inner_join(training_testing_artist_ids$training, by = "artist_id")

track_data_to_predict_tbl <- track_data_tbl %>%
  # Inner join to testing partition
  inner_join(training_testing_artist_ids$testing, by = "artist_id")
  
 # # Gradient boosted trees: modeling --------------------------------------------------------- Bombastic boosting! Spark machine learning functions are easy to use!
 > # track_data_to_model_tbl has been pre-defined
> track_data_to_model_tbl
# Source:   table<track_data> [?? x 14]
# Database: spark_connection
   artist_id  year timbre_means1 timbre_means2 timbre_means3 timbre_means4
   <chr>     <int>         <dbl>         <dbl>         <dbl>         <dbl>
 1 ARDNQ0R1~  1940          37.3         -70.2         39.4          12.7 
 2 ARDNQ0R1~  1940          33.3        -137.          54.5           3.59
 3 AR3MHG01~  1937          37.9         -17.8         54.8           3.61
 4 ARR6H6G1~  1934          30.8         -34.6         71.1          10.5 
 5 ARE2QID1~  1935          38.1          18.9         -2.48        -10.9 
 6 ARDNQ0R1~  1938          32.6        -118.          26.8          42.3 
 7 ARFUFNK1~  1938          35.8         -55.4         28.8          -8.34
 8 ARFUFNK1~  1938          43.0         -14.5          6.40        -15.3 
 9 ARDNQ0R1~  1938          32.7        -118.          27.1          43.7 
10 ARE2QID1~  1938          32.9        -136.          21.6         -11.0 
# ... with 646 more rows, and 8 more variables: timbre_means5 <dbl>,
#   timbre_means6 <dbl>, timbre_means7 <dbl>, timbre_means8 <dbl>,
#   timbre_means9 <dbl>, timbre_means10 <dbl>, timbre_means11 <dbl>,
#   timbre_means12 <dbl>
> 
> feature_colnames <- track_data_to_model_tbl %>%
    # Get the column names
    colnames() %>%
    # Limit to the timbre columns
    str_subset(fixed("timbre"))
> 
> gradient_boosted_trees_model <- track_data_to_model_tbl %>%
    # Run the gradient boosted trees model
    ml_gradient_boosted_trees("year", feature_colnames )
* No rows dropped by 'na.omit' call

###   Gradient boosted trees: prediction -----------------------------------------------------------------------
predicted_vs_actual <- testing_data %>%
  select(response) %>%
  collect() %>%
  mutate(predicted_response = predict(a_model, testing_data))
  
# training, testing sets & model 
track_data_to_model_tbl
track_data_to_predict_tbl    
gradient_boosted_trees_model  

responses <- track_data_to_predict_tbl %>%
  # Select the year column
  select(year) %>%
  # Collect the results
  collect() %>%
  # Add in the predictions
  mutate(
    predicted_year = predict(
    gradient_boosted_trees_model  ,
      track_data_to_predict_tbl
    )
  )

## Peerless plotting! You can use response scatter plots and residual density plots with any type of model.
# Draw a scatterplot of predicted vs. actual
ggplot(responses, aes(actual, predicted)) +
  # Add the points
  geom_point(alpha = 0.1) +
  # Add a line at actual = predicted
  geom_abline(intersept = 0, slop = 1)

residuals <- responses %>%
  # Transmute response data to residuals
  transmute(residual = predicted-actual)

# Draw a density plot of residuals
ggplot(residuals, aes(residual)) +
    # Add a density curve
    geom_density() +
    # Add a vertical line through zero
    geom_vline(xintercept = 0)

## =====================Random Forest: modeling===============================
